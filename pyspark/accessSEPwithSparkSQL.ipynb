{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new environment to keep things isolated\n",
    "```\n",
    "pyenv virtualenv sepspark\n",
    "pyenv activate sepspark\n",
    "```\n",
    "### Install the required modules\n",
    "`pip install pyspark trino pystarburst`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"custkey\"  |\"name\"              |\"address\"                              |\"nationkey\"  |\"phone\"          |\"acctbal\"  |\"mktsegment\"  |\"comment\"                                           |\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|1          |Customer#000000001  |IVhzIApeRb ot,c,E                      |15           |25-989-741-2988  |711.56     |BUILDING      |to the even, regular platelets. regular, ironic...  |\n",
      "|2          |Customer#000000002  |XSTf4,NCwDVaWNe6tEgvwfmRchLXak         |13           |23-768-687-3665  |121.65     |AUTOMOBILE    |l accounts. blithely ironic theodolites integra...  |\n",
      "|3          |Customer#000000003  |MG9kdTD2WBHm                           |1            |11-719-748-3364  |7498.12    |AUTOMOBILE    | deposits eat slyly ironic, even instructions. ...  |\n",
      "|4          |Customer#000000004  |XxVSJsLAGtn                            |4            |14-128-190-5944  |2866.83    |MACHINERY     | requests. final, regular ideas sleep final accou   |\n",
      "|5          |Customer#000000005  |KvpyuHCplrB84WgAiGV6sYpZq7Tj           |3            |13-750-942-6364  |794.47     |HOUSEHOLD     |n accounts will have to unwind. foxes cajole accor  |\n",
      "|6          |Customer#000000006  |sKZz0CsnMD7mp4Xd0YrBvx,LREYKUWAh yVn   |20           |30-114-968-4951  |7638.57    |AUTOMOBILE    |tions. even deposits boost according to the sly...  |\n",
      "|7          |Customer#000000007  |TcGe5gaZNgVePxU5kRrvXBfkasDTea         |18           |28-190-982-9759  |9561.95    |AUTOMOBILE    |ainst the ironic, express theodolites. express,...  |\n",
      "|8          |Customer#000000008  |I0B10bB0AymmC, 0PrRYBCP1yGJ8xcBPmWhl5  |17           |27-147-574-9335  |6819.74    |BUILDING      |among the slyly regular theodolites kindle blit...  |\n",
      "|9          |Customer#000000009  |xKiAFTjUsCuxfeleNqefumTrjS             |8            |18-338-906-3675  |8324.07    |FURNITURE     |r theodolites according to the requests wake th...  |\n",
      "|10         |Customer#000000010  |6LrEaV6KR6PLVcgl2ArL Q3rqzLzcT1 v2     |5            |15-741-346-9870  |2753.54    |HOUSEHOLD     |es regular deposits haggle. fur                     |\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lets try to access the Trino Query using the spark\n",
    "import os\n",
    "import trino\n",
    "from pyspark.sql import SparkSession\n",
    "from pystarburst import Session\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SEP Sparked\") \\\n",
    "    .master(\"local\") \\\n",
    "    .config(\"spark.jars\", \"./trino-jdbc-435.jar\") \\\n",
    "    .config(\"spark.driver.extraClassPath\", \"./trino-jdbc-435.jar\") \\\n",
    "    .config(\"spark.executor.extraClassPath\", \"./trino-jdbc-435.jar\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "# Define the JDBC connection properties\n",
    "url = \"jdbc:trino://XXXURLXXXX\"\n",
    "\n",
    "# Read data from the database using Spark JDBC\n",
    "df = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"driver\",\"io.trino.jdbc.TrinoDriver\") \\\n",
    "    .option(\"url\", url) \\\n",
    "    .option(\"dbtable\", \"customer\") \\\n",
    "    .option(\"roles\",\"system:sysadmin\") \\\n",
    "    .option(\"user\",\"XXUSERXXX\") \\\n",
    "    .load()\n",
    "\n",
    "# Show the dataframe\n",
    "df.show()\n",
    "\n",
    "# Lets use the PyStarburst to connect to the Trino\n",
    "# Create a PyStarburst session\n",
    "# Connect to SEP\n",
    "SEPConnStr = {\n",
    "    \"host\": \"http://XXXXURLXXXX\",\n",
    "    \"port\": 8080,\n",
    "    \"user\": \"XXXXXUSERXXXXXX\",\n",
    "    \"roles\": {\"system\": \"sysadmin\"},\n",
    "}\n",
    "session = Session.builder.configs(SEPConnStr).create()\n",
    "psdf = session.table(\"tpch.tiny.customer\").show()\n",
    "\n",
    "# Lets create an empty SparkDataframe and fetch the results to the SparkDataframe\n",
    "spark_df = spark.createDataFrame([], df.schema)\n",
    "spark_df = session.table(\"tpch.tiny.customer\").limit(20)\n",
    "spark_df.show()\n",
    "\n",
    "# Stop the SparkSession\n",
    "spark.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sepspark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
